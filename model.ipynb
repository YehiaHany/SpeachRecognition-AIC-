{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# from keras.models import Sequential\n",
    "from keras import layers, models, applications\n",
    "# from IPython.display import display, Markdown, Latex\n",
    "# from sklearn.datasets import make_blobs\n",
    "# from matplotlib.widgets import Slider\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset\n",
    "The dataset is a collection of mfcc, mfcc derivative, chroma features, beat events, etc..\n",
    "\n",
    "\n",
    "Feature extraction done using Librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (50715, 166)\n",
      "Adaptation data shape: (50715, 166)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.load(\"D:/programming/python/speech recognition/competition/SpeachRecognition-AIC-/preprocessed_data/train_data.npz\")\n",
    "train_features = train_data['features']\n",
    "train_labels = train_data['labels']\n",
    "\n",
    "adapt_data = np.load(\"D:/programming/python/speech recognition/competition/SpeachRecognition-AIC-/preprocessed_data/train_data.npz\")\n",
    "adapt_features = adapt_data['features']\n",
    "adapt_labels = adapt_data['labels']\n",
    "\n",
    "print(\"Train data shape:\", train_features.shape)\n",
    "print(\"Adaptation data shape:\", adapt_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seeing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50715,)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model\n",
    "\n",
    "## This model is designed as following:\n",
    "### a combined vgg-16 model in series with transformer architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 1584, 5, 512), dtype=float32, sparse=False, name=keras_tensor_59>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assume the input shape is (height, width, 1) for single-channel data\n",
    "input_shape = (50715, 166, 1)  # Example shape; adjust according to your data\n",
    "\n",
    "# Define the input layer with the new shape\n",
    "inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "# Convert single channel to 3 channels by repeating the input across the channel dimension\n",
    "x = layers.Conv2D(3, (3, 3), padding='same')(inputs)\n",
    "\n",
    "# Load the VGG16 model without the top layers or any weights\n",
    "vgg_model = tf.keras.applications.VGG16(include_top=False, input_tensor=x, weights=None)\n",
    "shapes_vgg = vgg_model.output\n",
    "\n",
    "shapes_vgg\n",
    "# we have to train the whole model so no need to freeze the weights "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim)]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 8\n",
    "embed_dim = shapes_vgg.shape[-1]  # Should match the last dimension of VGG output\n",
    "ff_dim = 2048\n",
    "transformer_layers = 4  # Number of transformer layers\n",
    "num_classes = 10  # Number of output classes for speech recognition\n",
    "\n",
    "# Reshape the VGG output to fit the transformer input requirements\n",
    "x = layers.Reshape((-1, embed_dim))(x)\n",
    "\n",
    "# Add Transformer layers\n",
    "for _ in range(transformer_layers):\n",
    "    x = TransformerBlock(embed_dim, num_heads, ff_dim)(x)\n",
    "\n",
    "# Add Global Average Pooling and Output Layer\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model architecture\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
